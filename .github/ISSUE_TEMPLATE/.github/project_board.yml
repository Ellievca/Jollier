# .github/project_board.yml
name: "ğŸ¹ Hand Composer â€“ AMD Hackathon Project"
description: "A gesture-based music visualizer powered by AMD ROCm + FSR"
public: true

# Columns for your Kanban board
columns:
  - name: ğŸ Backlog
    description: "Ideas, unstarted tasks, or notes to triage."
  - name: ğŸš§ In Progress
    description: "Active development tasks."
  - name: ğŸ§ª Testing
    description: "Tasks ready for or undergoing testing."
  - name: âœ… Done
    description: "Completed tasks and deliverables."

# Automatically create cards under each phase
draft_issues:
  - title: "Set up environment & verify AMD ROCm"
    body: |
      - [ ] Install dependencies (OpenCV, MediaPipe, PyTorch ROCm)
      - [ ] Verify GPU visibility (`rocminfo`, `torch.version.hip`)
      - [ ] Initialize Git repo + .gitignore
    labels: ["setup", "mvp"]
    column: ğŸ Backlog

  - title: "Implement webcam capture & hand landmarks"
    body: |
      - [ ] Capture webcam frames via OpenCV
      - [ ] Integrate MediaPipe Hands â†’ draw landmarks
      - [ ] Display FPS and latency
    labels: ["vision", "mvp"]
    column: ğŸš§ In Progress

  - title: "Map gestures to chords (rule-based)"
    body: |
      - [ ] Right-hand Y â†’ chord root
      - [ ] Left-hand pose â†’ major/minor/7/sus
      - [ ] Hand spread â†’ velocity
      - [ ] Hands distance â†’ tempo
    labels: ["music-engine", "mvp"]
    column: ğŸš§ In Progress

  - title: "Integrate MIDI output"
    body: |
      - [ ] Create virtual MIDI port (mido/python-rtmidi)
      - [ ] Play chords through Fluidsynth or DAW
      - [ ] Confirm latency under 100 ms
    labels: ["audio", "mvp"]
    column: ğŸš§ In Progress

  - title: "Basic visualizer (PyGame)"
    body: |
      - [ ] Show FPS, chord name, tempo
      - [ ] Animate simple shapes on note-on events
      - [ ] Display inference time
    labels: ["visualizer", "mvp"]
    column: ğŸ§ª Testing

  - title: "Train ROCm-accelerated gesture classifier"
    body: |
      - [ ] Collect dataset of labeled gestures
      - [ ] Train MLP/LSTM on AMD Developer Cloud
      - [ ] Export TorchScript model
      - [ ] Compare CPU vs ROCm inference performance
    labels: ["ai", "rocm", "polish"]
    column: ğŸš§ In Progress

  - title: "Upgrade visualizer to Unity/Unreal + FSR 4"
    body: |
      - [ ] Move rendering to game engine
      - [ ] Integrate FidelityFX Super Resolution 4 for upscaling
      - [ ] Add particle and lighting effects synced to velocity
    labels: ["fsr", "visuals", "polish"]
    column: ğŸ§ª Testing

  - title: "Create architecture diagram & README"
    body: |
      - [ ] Diagram: Capture â†’ Perception â†’ Music â†’ Viz
      - [ ] Document ROCm, FSR, and AMD Cloud usage
      - [ ] Include setup and demo instructions
    labels: ["docs", "presentation"]
    column: ğŸ Backlog

  - title: "Record demo video + live script"
    body: |
      - [ ] 30â€“60 s recording showing gestures + HUD + visuals
      - [ ] Prepare 90-second live pitch script
      - [ ] Capture CPU vs GPU benchmark overlay
    labels: ["presentation", "final"]
    column: ğŸ§ª Testing

  - title: "Deliver final demo at hackathon"
    body: |
      - [ ] Confirm AMD ROCm + FSR performance proof
      - [ ] Polish visuals and latency metrics
      - [ ] Sync audio/video for live performance
      - [ ] Push final build to repo
    labels: ["demo", "deadline"]
    column: âœ… Done
